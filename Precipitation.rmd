---
title: "Precipitation"
author: "Erika W"
date: "3/30/2021"
output:
  html_document:
    code_download: true
    keep_md: true
    toc: true
    toc_float:
      toc_collapsed: true
    toc_depth: 3
    theme: lumen
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, message = F}
library(tidyverse)
library(data.table)
library(xts)
library(sf)
library(here)
library(readxl)
library(RColorBrewer)
library(zoo)
library(lubridate)
library(ggplot2)
```
## Load Data

### Precipitation

In October 2020, Steven Eikenbary created a 4x4km grid of the SF delta study area in ArcMap, and retrieved the lat/longs of the center points in each grid. Those coordinates can be found at:

URL

On October 26, 2020, precipitation data was downloaded from PRISM for that grid of coordinates (n=33) using the multiple sites downloader: https://prism.oregonstate.edu/explorer/bulk.php

Data were downloaded for every water year between 2009 through 2019, for all locations within the grid.

The spatial resolution of the data is 4km, and it was sourced from the AN81d dataset. Precipitation includes rainfall + melted snowfall. Additional details about the data can be found at: http://www.prism.oregonstate.edu/documents/PRISM_datasets.pdf

```{r, echo=F }
## Load precip data
df2010 <- fread("https://github.com/WWU-IETC-R-Collab/Seasonal/raw/master/Data/PRISM_Edited/PRISM_WY2010.csv") %>%
  mutate(WaterYear = "2010")

df2011 <- fread("https://github.com/WWU-IETC-R-Collab/Seasonal/raw/master/Data/PRISM_Edited/PRISM_WY2011.csv") %>%
  mutate(WaterYear = "2011")

df2012 <- fread("https://github.com/WWU-IETC-R-Collab/Seasonal/raw/master/Data/PRISM_Edited/PRISM_WY2012.csv")%>%
  mutate(WaterYear = "2012")

df2013 <- fread("https://github.com/WWU-IETC-R-Collab/Seasonal/raw/master/Data/PRISM_Edited/PRISM_WY2013.csv")%>%
  mutate(WaterYear = "2013")

df2014 <- fread("https://github.com/WWU-IETC-R-Collab/Seasonal/raw/master/Data/PRISM_Edited/PRISM_WY2014.csv")%>%
  mutate(WaterYear = "2014")

df2015 <- fread("https://github.com/WWU-IETC-R-Collab/Seasonal/raw/master/Data/PRISM_Edited/PRISM_WY2015.csv")%>%
  mutate(WaterYear = "2015")

df2016 <- fread("https://github.com/WWU-IETC-R-Collab/Seasonal/raw/master/Data/PRISM_Edited/PRISM_WY2016.csv")%>%
  mutate(WaterYear = "2016")

df2017 <- fread("https://github.com/WWU-IETC-R-Collab/Seasonal/raw/master/Data/PRISM_Edited/PRISM_WY2017.csv")%>%
  mutate(WaterYear = "2017")

df2018 <- fread("https://github.com/WWU-IETC-R-Collab/Seasonal/raw/master/Data/PRISM_Edited/PRISM_WY2018.csv")%>%
  mutate(WaterYear = "2018")

df2019 <- fread("https://github.com/WWU-IETC-R-Collab/Seasonal/raw/master/Data/PRISM_Edited/PRISM_WY2019.csv")%>%
  mutate(WaterYear = "2019")

```

<br/>


### USFE Risk Regions
```{r}
# Load Risk Regions from GitHub CEDEN repository (change if moved)

USFE.RiskRegions.z <- "https://github.com/WWU-IETC-R-Collab/CEDEN-mod/raw/main/Data/USFE_RiskRegions_9292020.zip"

unzip_shape <- function(InputShapeZip){
  dl.temp <- tempfile() # Create local temp file for zipped shapefile
  dl.temp2 <- tempfile() # Create a second local temp file to store unzipped shapefile
  download.file(InputShapeZip, dl.temp, quiet=T) # Downloads zip file from InputShape
  unzip(zip = dl.temp, exdir = dl.temp2) # Unzips zip file
  shapefile.out <-list.files(dl.temp2, pattern = ".shp$",full.names=TRUE) # stores file path of files with .shp ext in dl.temp2
  sf::st_read(shapefile.out) # Reads shapefile as sf object
}

USFE.RiskRegions <- unzip_shape(USFE.RiskRegions.z) # CRS is WGS 84
```

<br/>

### CEDENSURF

I have read in the combined modified CEDEN and SURF data, but I believe that it may be most useful to jump right to the wide format data...

```{r}
CEDENSURFMod <- fread("https://github.com/WWU-IETC-R-Collab/CEDENSURF-mod/raw/main/Data/Output/CEDENSURFMod.csv")

```

<br/>
<br/>

## Data Prep

1. Combine water years
2. Make shapefile
3. Join to risk regions
4. Summarize: max precipitation observed within grid by risk region
*Steven had summarised precip using MAX - why not mean?*

```{r, message = F, warning = F}
## Combine data

AllWY <- rbind(df2010, df2011, df2012, df2013,
               df2014, df2015, df2016, df2017,
               df2018, df2019)

rm(df2010, df2011, df2012, df2013,
   df2014, df2015, df2016,df2017,
   df2018, df2019) # clean up global environment

## Modify data

AllWY<- AllWY %>%
  mutate(Date = as.Date(AllWY$Date, "%m/%d/%Y")) %>%
  filter(!is.na(Date))

## Create zoo

AllWY.zoo <-zoo(AllWY, as.Date(AllWY$Date))

## Create sf

AllWY.sf <- st_as_sf(AllWY, coords = c("Longitude", "Latitude"), remove = F, crs = "WGS84")

## Join to Risk Regions

AllWY.sf <- st_join(AllWY.sf, USFE.RiskRegions[1], left = T) %>%
  filter(!is.na(Subregion)) 

AllWY <- AllWY.sf %>% st_set_geometry(NULL)

```

```{r, message = F, warning = F}
## Summarize precip by dates within each RR.
AllWY_max <- AllWY %>%
  group_by(Date, Subregion, WaterYear) %>%
  summarize(max_precip = max(ppt_in))
```

## Define Seasons

**What qualifies as the wet season?**

In each region I observed, November - March appeared to be the wettest seasons

According to Alameda WETS tables, during those months

- At the inland edge of the estuary, average monthly precip is only 2.5-3" (< 0.1" per day)

- At the SE border of our study area, average monthly precip is only 1.5 - 2" (<0.07"/day)

*Question: what are stronger predictors of water quality parameters?*

Daily water volume definitions
A. Wet being >0.1" in a day *(current)*
B. Wet being >0.2" in a day 

Date buffer definitions
A. 7 days  *(current)*
B. 3 days

**Current process**

Moving forward with Wet being within 7 days of a day with rain event >= 0.05", I added a column to CEDENSURF defining Season.

By changing Stevens code to be a loop, it allowed wet vs dry season to be defined differently for each region on a given date.

```{r}
# Subset and define wet period for each region

Region<- unique(AllWY_max$Subregion)

result <- list()

for(i in 1:6){
  m<- AllWY_max %>% filter(Subregion == Region[i])
  
  wet_event <- subset(m, max_precip >= 0.05)

  oneweek <- wet_event %>% 
  group_by(Date) %>% 
  complete(Date = seq.Date((Date), (Date+7), by = 'days'))

  PRISM_wet <- subset(m, Date %in% oneweek$Date)
  PRISM_wet$Season.1 <- "wet"
  
  PRISM_dry <- subset(m, !(Date %in% oneweek$Date))
  PRISM_dry$Season.1 <- "dry"
  
  result[[i]]<-rbind(PRISM_wet, PRISM_dry)
  }

AllWY_max <- do.call(rbind, result)
```

#### Explore outcome

Which months ended up with "wet" vs "dry" seasons?

```{r}
AllWY_max <- AllWY_max %>% mutate(Month = month(Date))

boxplot(max_precip ~ Month, data = AllWY_max)

AllWY_max %>% 
  group_by(Month, Season.1, Subregion) %>%
  summarize(Subregion = first(Subregion),
            Sum = n()) %>%
  pivot_wider(names_from = Season.1,
              names_repair = "check_unique",
              values_from = Sum) # Values to fill columns

AllWY_max %>% 
  group_by(Month, Season.1) %>%
  summarize(Sum = n()) %>%
  pivot_wider(names_from = Season.1,
              names_repair = "check_unique",
              values_from = Sum) # Values to fill columns
```


### Seasons via rolling average

I think that it may make most sense to allow a rolling average to be used to reduce incursions of "dry" season within "wet" seasons and vice versa. 

```{r}

library(RcppRoll)

Region<- unique(AllWY_max$Subregion)

result <- list()

for(i in 1:6){
  m<- AllWY_max %>% filter(Subregion == Region[i])
  m$d14_precipavg <- roll_mean(m$max_precip, n=14, align = "center", fill = NA)
  result[[i]]<- m
}

AllWY_max <- do.call(rbind, result)
```

Trying this with the same 7 day buffer, we find:

```{r}
# Subset and define wet period for each region

Region<- unique(AllWY_max$Subregion)

result <- list() # empty list to store iterated results from loop

for(i in 1:6){
  m<- AllWY_max %>% filter(Subregion == Region[i])
  
  wet_event <- subset(m, d14_precipavg >= 0.05)

  oneweek <- wet_event %>% 
  group_by(Date) %>% 
  complete(Date = seq.Date((Date), (Date+7), by = 'days')) # fills 7 days beyond each 'wet' date

  PRISM_wet <- subset(m, Date %in% oneweek$Date)
  PRISM_wet$Season.r <- "wet"
  
  PRISM_dry <- subset(m, !(Date %in% oneweek$Date))
  PRISM_dry$Season.r <- "dry"
  
  result[[i]]<-rbind(PRISM_wet, PRISM_dry)
  }

AllWY_max <- do.call(rbind, result) # recombine all 6 result df
```

#### Explore outcome

Which months ended up with "wet" vs "dry" seasons?

```{r}
AllWY_max <- AllWY_max %>% mutate(Month = month(Date))

boxplot(max_precip ~ Month, data = AllWY_max)

AllWY_max %>% 
  group_by(Month, Season.r, Subregion) %>%
  summarize(Subregion = first(Subregion),
            Sum = n()) %>%
  pivot_wider(names_from = Season.r,
              names_repair = "check_unique",
              values_from = Sum) # Values to fill columns

AllWY_max %>% 
  group_by(Month, Season.r) %>%
  summarize(Sum = n()) %>%
  pivot_wider(names_from = Season.r,
              names_repair = "check_unique",
              values_from = Sum) # Values to fill columns
```

## Prepare for NETICA {.tabset}

Tabs below have the following process repeated for three datasets: two files prepared for the final NETICA - one df for water and one df for sediment, and a small subset used to test the format compatibility with Netica.

The process used to prepare the data is:

1. Join Seasons data with the wide format CEDENSURF (created via steps documented in the data-splitting rmd). 

2. Reformat to meet requirements for Netica

    Values should match how they will appear in NETICA
    
    * Region - change to names w/o spaces
    * NA --> *

3. Save as txt

### Sediment

```{r}
# Load CEDENSURF Data (wide format)
Sed_Wide <- fread("https://github.com/WWU-IETC-R-Collab/CEDENSURF-data.splitting/raw/main/Data/Output/Allsed.Wide.csv") 
    
# Join CEDENSURF to AllWY_max
CS_PRISM<- merge(Sed_Wide, AllWY_max, by = c("Date", "Subregion"))
```

```{r}
# Merge with season data

CS_PRISM<- merge(Sed_Wide, AllWY_max, by = c("Date", "Subregion"))

# Rename regions

CS_PRISM <- CS_PRISM %>% 
  mutate(Region = Subregion) %>%
  mutate(Region = str_replace(Region, "Central Delta", "Central")) %>%
  mutate(Region = str_replace(Region, "North Delta", "North")) %>%
  mutate(Region = str_replace(Region, "Sacramento River", "Sacramento")) %>%
  mutate(Region = str_replace(Region, "South Delta", "South")) %>%
  mutate(Region = str_replace(Region, "Suisun Bay", "Suisun"))

# Remove unnecessary columns

ForNetica <- CS_PRISM %>% select(!c(Subregion, Latitude, Longitude, Date, WaterYear, max_precip, d14_precipavg))

# Replace NA with *, which is how Netica deals with NA

ForNetica <- mutate_all(ForNetica, ~replace(., is.na(.), "*"))

# Save

write.csv(x = ForNetica, file = "Data/Output/AllSed_ForNetica.csv", 
          row.names = F)

write.table(x = ForNetica, file = "Data/Output/AllSed_ForNetica.txt", sep = "")

```

### Water 
```{r}
## For example using Water Quality Parameters Subset and my limited-mode netica, I used just the WQP.Wide.water dataset:

# Load CEDENSURF Data (wide format)
Water_Wide <- fread("https://github.com/WWU-IETC-R-Collab/CEDENSURF-data.splitting/raw/main/Data/Output/Allwater.Wide.csv") 
    
# Join CEDENSURF to AllWY_max
CS_PRISM<- merge(Water_Wide, AllWY_max, by = c("Date", "Subregion"))
```

```{r}
# Merge with season data

CS_PRISM<- merge(Water_Wide, AllWY_max, by = c("Date", "Subregion"))

# Rename regions

CS_PRISM <- CS_PRISM %>% 
  mutate(Region = Subregion) %>%
  mutate(Region = str_replace(Region, "Central Delta", "Central")) %>%
  mutate(Region = str_replace(Region, "North Delta", "North")) %>%
  mutate(Region = str_replace(Region, "Sacramento River", "Sacramento")) %>%
  mutate(Region = str_replace(Region, "South Delta", "South")) %>%
  mutate(Region = str_replace(Region, "Suisun Bay", "Suisun"))

# Remove unnecessary columns

ForNetica <- CS_PRISM %>% select(!c(Subregion, Latitude, Longitude, Date, WaterYear, max_precip, d14_precipavg))

# Replace NA with *, which is how Netica deals with NA

ForNetica <- mutate_all(ForNetica, ~replace(., is.na(.), "*"))

# Save

write.csv(x = ForNetica, file = "Data/Output/AllWater_ForNetica.csv", 
          row.names = F)

write.table(x = ForNetica, file = "Data/Output/AllWater_ForNetica.txt", sep = "")
```

### Mini 
```{r}
## For example using Water Quality Parameters Subset and my limited-mode netica, I used just the WQP.Wide.water dataset:

# Load CEDENSURF Data (wide format)
WQ_Wide <- fread("https://github.com/WWU-IETC-R-Collab/CEDENSURF-data.splitting/raw/main/Data/Output/Subsets/WQP.Wide.water.csv") 
    
# Join CEDENSURF to AllWY_max
CS_PRISM<- merge(WQ_Wide, AllWY_max, by = c("Date", "Subregion"))
```

```{r}
# Merge with season data

CS_PRISM<- merge(WQ_Wide, AllWY_max, by = c("Date", "Subregion"))

# Rename regions

CS_PRISM <- CS_PRISM %>% 
  mutate(Region = Subregion) %>%
  mutate(Region = str_replace(Region, "Central Delta", "Central")) %>%
  mutate(Region = str_replace(Region, "North Delta", "North")) %>%
  mutate(Region = str_replace(Region, "Sacramento River", "Sacramento")) %>%
  mutate(Region = str_replace(Region, "South Delta", "South")) %>%
  mutate(Region = str_replace(Region, "Suisun Bay", "Suisun"))

# Remove unnecessary columns

ForNetica <- CS_PRISM %>% select(!c(Subregion, Latitude, Longitude, Date, WaterYear, max_precip, d14_precipavg))

# Replace NA with *, which is how Netica deals with NA

ForNetica <- mutate_all(ForNetica, ~replace(., is.na(.), "*"))

# Save

write.csv(x = ForNetica, file = "Data/Output/WQP_ForNetica.csv", 
          row.names = F)

write.table(x = ForNetica, file = "Data/Output/WQP_ForNetica.txt", sep = "")

```

**On a Windows, Netica should be able to use the csv file directly. I found that in order for it to allocate continuously variables appropriately into the designated bins (ie: when MANY nodes were in one document), it needed to be a txt file. Re-saving the csv as txt worked fine, I also added code here to write directly to txt. **

