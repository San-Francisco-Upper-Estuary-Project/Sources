knitr::opts_chunk$set(echo = TRUE)
# Function to Tabulate raster::extract() Output by Polygon
# http://zevross.com/blog/2015/03/30/map-and-analyze-raster-data-in-r/
tabFunc <- function(indx, extracted, region, regname) {
dat<-as.data.frame(table(extracted[[indx]]))
dat$name<-region[[regname]][[indx]]
return(dat)
}
# Function for converting pixel count to square kilometers
pc2sqkm <- function(x, in_raster) {
apc <- prod(raster::res(in_raster))
x * apc / 1e+6
}
# Create NLCD Class Key
# Based on: https://www.mrlc.gov/data/legends/national-land-cover-database-2016-nlcd2016-legend
NLCD.class <- c('OpenWater' = '11',
'PerennialIceSnow' = '12',
'DevOpenSpace' = '21',
'DevLowInt' = '22',
'DevMedInt' = '23',
'DevHighInt' = '24',
'BarrenLand' = '31',
'DeciduousForest' = '41',
'EvergreenForest' = '42',
'DwarfShrub' = '51',
'ShrubScrub' = '52',
'GrassHerb' = '71',
'SedgeHerb' = '72',
'Lichens' = '73',
'Moss' = '74',
'PastureHay' = '81',
'CultivatedCrops' = '82',
'WoodyWetlands' = '90',
'EmergentHerbWetlands' = '95'
)
# Load Risk Regions
USFE.riskregions.z <- "https://github.com/WWU-IETC-R-Collab/CEDEN-mod/raw/main/Data/USFE_RiskRegions_9292020.zip"
USFE.riskregions <- IETC::unzipShape(USFE.riskregions.z) # loads GitHub zipped shapefile as an sf object
# Visualize
ggplot() +
geom_sf(data = USFE.riskregions, fill = NA) +
ggtitle("USFE Risk Regions")
# Visualize
ggplot() +
geom_sf(data = USFE.riskregions, fill = NA) +
ggtitle("USFE Risk Regions")
#devtools::install_github("WWU-IETC-R-Collab/IETC")
library(IETC)
#devtools::install_github("ropensci/FedData") # Use Fed Data Version 3.0.0 or higher. CRAN has 2.5.7
library(FedData)
library(rgdal) # R geoprocessing tools
library(raster) # Raster data manipulation
library(sf) # vector data manipulation
library(tidyverse)
# Load Risk Regions
USFE.riskregions.z <- "https://github.com/WWU-IETC-R-Collab/CEDEN-mod/raw/main/Data/USFE_RiskRegions_9292020.zip"
USFE.riskregions <- IETC::unzipShape(USFE.riskregions.z) # loads GitHub zipped shapefile as an sf object
# Visualize
ggplot() +
geom_sf(data = USFE.riskregions, fill = NA) +
ggtitle("USFE Risk Regions")
tibble(USFE.riskregions)
# Load Land Use Data using FedData
# Alternative NLCD data at mrlc.gov/viewer using the following extent
# Latitude dd: 36.75543, 38.92584
# Longitude dd: -123.72037, -120.52298
# https://www.mrlc.gov/viewer/?downloadBbox=36.75543,38.92584,-123.72037,-120.52298
# Get the NLCD (USA ONLY)
# Returns a raster
USFE.NLCD <- get_nlcd(template = USFE.riskregions,
year = 2016,
dataset = "Land_Cover",
label = "USFE")
# raster::plot(USFE.NLCD, main = "NLCD Data, 2016")
# Transform Risk Regions to match raster data
USFE.riskregions.NLCD <- as_Spatial(st_zm(USFE.riskregions)) %>%
spTransform(crs(USFE.NLCD))
# Mask Study Area
USFE.NLCD.mask <- raster::mask(USFE.NLCD, USFE.riskregions.NLCD)
# Check Plot with raster::plot
raster::plot(USFE.NLCD.mask, main = "2016 NLCD within \n USFE Risk Regions")
# Extract Raster Values
USFE.LULC <- raster::extract(USFE.NLCD.mask, USFE.riskregions.NLCD) # be patient, this takes a while
# Tabulate raster::extract() lists
USFE.LULC.tabulated <- lapply(seq(USFE.LULC),
tabFunc, USFE.LULC,USFE.riskregions.NLCD,
"Subregion") %>% # tabulate result lists from raster::extract
do.call("rbind", .) %>% # combine the tabulated raster::extract
pivot_wider(names_from = Var1, # pivot classes wide
values_from = Freq) %>%
dplyr::select(name, any_of(NLCD.class)) %>% # replace column class ID # with class name
mutate(across(where(is.numeric), ~pc2sqkm(., USFE.NLCD.mask))) # convert pixel counts to sq km
# Extract Raster Values
USFE.LULC <- raster::extract(USFE.NLCD.mask, USFE.riskregions.NLCD) # be patient, this takes a while
# Tabulate raster::extract() lists
USFE.LULC.tabulated <- lapply(seq(USFE.LULC),
tabFunc, USFE.LULC,USFE.riskregions.NLCD,
"Subregion") %>% # tabulate result lists from raster::extract
do.call("rbind", .) %>% # combine the tabulated raster::extract
pivot_wider(names_from = Var1, # pivot classes wide
values_from = Freq) %>%
dplyr::select(name, any_of(NLCD.class)) %>% # replace column class ID # with class name
mutate(across(where(is.numeric), ~pc2sqkm(., USFE.NLCD.mask))) # convert pixel counts to sq km
View(pc2sqkm)
View(USFE.riskregions)
View(USFE.LULC.tabulated)
USFE.LULC.tabulated <- USFE.LULC.tabulated %>%
rename(Subregion = name) %>%
replace(is.na(.), 0) %>%
mutate(TotKm = rowSums(.[,-c(1,2)])) %>% # calculate total km of subregion land use classes
mutate(PercHighIntens = 100*DevHighInt/TotKm) %>%
mutate(PercAgri = 100*CultivatedCrops/TotKm)
# Write Final Table to Outputs
write_csv(USFE.LULC.tabulated, "Output/NLCD_LULC.csv")
View(USFE.LULC.tabulated)
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(tidyverse)
library(data.table)
library(sf)
library(here)
library(ggplot2)
# Risk Regions from GitHub CEDEN repository (change if moved)
USFE.RiskRegions.z <- "https://github.com/WWU-IETC-R-Collab/CEDEN-mod/raw/main/Data/USFE_RiskRegions_9292020.zip"
unzip_shape <- function(InputShapeZip){
dl.temp <- tempfile() # Create local temp file for zipped shapefile
dl.temp2 <- tempfile() # Create a second local temp file to store unzipped shapefile
download.file(InputShapeZip, dl.temp, quiet=T) # Downloads zip file from InputShape
unzip(zip = dl.temp, exdir = dl.temp2) # Unzips zip file
shapefile.out <-list.files(dl.temp2, pattern = ".shp$",full.names=TRUE) # stores file path of files with .shp ext in dl.temp2
sf::st_read(shapefile.out) # Reads shapefile as sf object
}
USFE.RiskRegions <- unzip_shape(USFE.RiskRegions.z) # CRS is WGS 84
# Precipitation Data from PRISM from Seasons repo
AllWY_max <-  fread("https://github.com/WWU-IETC-R-Collab/Seasonal/raw/master/Data/Output/USFE_Precip.csv")
# Load Land Use Data from GitHub LULC repo
LULC <- fread("https://github.com/WWU-IETC-R-Collab/LULC/raw/EW_Learning/Output/NLCD_LULC.csv") %>%
select(Subregion, PercHighIntens, PercAgri)
# CEDENSURF Sediment Data (wide format)
Sed_Wide <- fread("https://github.com/WWU-IETC-R-Collab/CEDENSURF-mod/raw/main/Data/Output/Allsed.Wide.csv")
# CEDENSURF Water Data (wide format)
Water_Wide <- fread("https://github.com/WWU-IETC-R-Collab/CEDENSURF-mod/raw/main/Data/Output/Allwater.Wide.csv")
# Join LULC to AllWY_max.
Source <- merge(AllWY_max, LULC, by = "Subregion")
# Join CEDENSURF to Source
CS_PRISM<- merge(Sed_Wide, Source, by = c("Date", "Subregion"))
# Merge with season data
CS_PRISM<- merge(Sed_Wide, Source, by = c("Date", "Subregion"))
# Rename regions
CS_PRISM <- CS_PRISM %>%
mutate(Region = Subregion) %>%
mutate(Region = str_replace(Region, "Central Delta", "Central")) %>%
mutate(Region = str_replace(Region, "North Delta", "North")) %>%
mutate(Region = str_replace(Region, "Sacramento River", "Sacramento")) %>%
mutate(Region = str_replace(Region, "South Delta", "South")) %>%
mutate(Region = str_replace(Region, "Suisun Bay", "Suisun"))
# Remove unnecessary columns
ForNetica <- CS_PRISM %>% select(!c(Subregion, Latitude, Longitude, Date, WaterYear, max_precip, d14_precipavg))
# Replace NA with *, which is how Netica deals with NA
ForNetica <- mutate_all(ForNetica, ~replace(., is.na(.), "*"))
# Save
write.csv(x = ForNetica, file = "Data/Output/AllSed_ForNetica.csv",
row.names = F)
# Join CEDENSURF to Source
CS_PRISM<- merge(Water_Wide, Source, by = c("Date", "Subregion"))
# Merge with season data
CS_PRISM<- merge(Water_Wide, Source, by = c("Date", "Subregion"))
# Rename regions
CS_PRISM <- CS_PRISM %>%
mutate(Region = Subregion) %>%
mutate(Region = str_replace(Region, "Central Delta", "Central")) %>%
mutate(Region = str_replace(Region, "North Delta", "North")) %>%
mutate(Region = str_replace(Region, "Sacramento River", "Sacramento")) %>%
mutate(Region = str_replace(Region, "South Delta", "South")) %>%
mutate(Region = str_replace(Region, "Suisun Bay", "Suisun"))
# Remove unnecessary columns
ForNetica <- CS_PRISM %>% select(!c(Subregion, Latitude, Longitude, Date, WaterYear, max_precip, d14_precipavg))
# Replace NA with *, which is how Netica deals with NA
ForNetica <- mutate_all(ForNetica, ~replace(., is.na(.), "*"))
# Save
write.csv(x = ForNetica, file = "Data/Output/AllWater_ForNetica.csv",
row.names = F)
# Writing directly to txt file does not play nice with Netica... Save as CSV then "save-as" txt
# write.table(x = ForNetica, file = "Data/Output/AllWater_ForNetica.txt", sep = "")
## For example using Water Quality Parameters Subset and my limited-mode netica, I used just the WQP.Wide.water dataset:
# Load CEDENSURF Data (wide format)
WQ_Wide <- fread("https://github.com/WWU-IETC-R-Collab/CEDENSURF-mod/raw/main/Data/Output/WideSubsets/WQP.Wide.water.csv")
# Join CEDENSURF to Source
CS_PRISM<- merge(WQ_Wide, Source, by = c("Date", "Subregion"))
# Merge with season data
CS_PRISM<- merge(WQ_Wide, Source, by = c("Date", "Subregion"))
# Rename regions
CS_PRISM <- CS_PRISM %>%
mutate(Region = Subregion) %>%
mutate(Region = str_replace(Region, "Central Delta", "Central")) %>%
mutate(Region = str_replace(Region, "North Delta", "North")) %>%
mutate(Region = str_replace(Region, "Sacramento River", "Sacramento")) %>%
mutate(Region = str_replace(Region, "South Delta", "South")) %>%
mutate(Region = str_replace(Region, "Suisun Bay", "Suisun"))
# Remove unnecessary columns
ForNetica <- CS_PRISM %>% select(!c(Subregion, Latitude, Longitude, Date, WaterYear, max_precip, d14_precipavg))
# Replace NA with *, which is how Netica deals with NA
ForNetica <- mutate_all(ForNetica, ~replace(., is.na(.), "*"))
# Save
write.csv(x = ForNetica, file = "Data/Output/WQP_ForNetica.csv",
row.names = F)
# Writing directly to txt file does not play nice with Netica... Save as CSV then "save-as" txt
# write.table(x = ForNetica, file = "Data/Output/WQP_ForNetica.txt", sep = "")
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(sf)
library(here)
library(readxl)
library(vegan)
# Read in wide-format data with Source and Stressor both.
SS_Water <- read_csv("Data/Output/AllWater_ForNetica.csv") %>% na_if(., "*")
SS_Water$Region <- as.factor(SS_Water$Region)
### Create dataframe with just WQ data
SS_Stressor <- SS_Water %>% select(!c(Region, Matrix, Seasonr, PercHighIntens, PercAgri))
SS_Source <- SS_Water %>% select(Region, Matrix, Seasonr, PercHighIntens, PercAgri)
View(SS_Stressor)
SS_Water %>%
summarise_if(is.numeric, length, na.rm = TRUE)
SS_Water %>%
summarise_if(is.numeric, mean, na.rm = TRUE)
SS_Water <- read_csv("Data/Output/AllWater_ForNetica.csv") %>% na_if(., "*")%>%
mutate(Region = factor) %>%
mutate(Seasonr = factor) %>%
mutate(Season01 = factor)
library(tidyverse)
library(sf)
library(here)
library(readxl)
library(vegan)
# Read in wide-format data with Source and Stressor both.
SS_Water <- read_csv("Data/Output/AllWater_ForNetica.csv") %>% na_if(., "*")
# All variables except character v's - some listed as character even though numeric. Fix that.
SS_Water[c(2:33, 37:38)] <- SS_Water[c(2:33, 37:38)] %>%
mutate_if(is.character,as.numeric)
# Define factors
SS_Water$Region <- as.factor(SS_Water$Region)
SS_Water %>%
summarise_if(is.numeric, mean, na.rm = TRUE)
SS_Water %>%
summarise_if(is.numeric, length, na.rm = TRUE)
SS_Water %>%
summarise_if(is.numeric, count, na.rm = TRUE)
SS_Water %>%
summarise_if(is.numeric, n, na.rm = TRUE)
SS_Water %>%
summarise_if(is.numeric, funs(n()), na.rm = TRUE)
SS_Water %>%
summarise_if(is.numeric, funs(n()))
SS_Water %>%
summarise_if(is.numeric, funs(n()), na.rm = TRUE)
SS_Water %>%
summarise_if(is.numeric, funs(n(), nmiss=sum(is.na(.))))
SS_Water %>%
summarise_if(is.numeric, funs(n(.), nmiss=sum(is.na(.))))
SS_Water %>%
summarise_if(is.numeric, funs(n(), nmiss=sum(is.na(.))))
summarise_if(is.numeric, funs(n()- nmiss=sum(is.na(.)))
SS_Water %>%
SS_Water %>%
summarise_if(is.numeric, funs(n()- nmiss=sum(is.na(.))))
SS_Water %>%
summarise_if(is.numeric, funs(n()- nmiss=sum(is.na(.))))
SS_Water %>%
summarise_if(is.numeric, funs((n()- nmiss=sum(is.na()))))
SS_Water %>%
summarise_if(is.numeric, funs((n(.)- nmiss=sum(is.na(.)))))
SS_Water %>%
summarise_if(is.numeric, funs(n()))
SS_Water %>%
summarise_if(is.numeric, funs(count = n(.) - sum(is.na(.))))
summarise_if(is.numeric, funs(c(count = n(.) - sum(is.na(.))))
SS_Water %>%
SS_Water %>%
summarise_if(is.numeric, funs(c(count = n(.) - sum(is.na(.)))))
SS_Water %>%
summarise_if(is.numeric, funs(c(count = n() - sum(is.na()))))
SS_Water %>%
summarise_if(is.numeric, funs(c(count = n() - sum(is.na()))))
SS_Water %>%
summarise_if(is.numeric, funs(sum(is.na()))))
SS_Water %>%
summarise_if(is.numeric, funs(sum(is.na())))
SS_Water %>%
summarise_if(is.numeric, funs(sum(is.na(.))))
SS_Water %>%
summarise_if(is.numeric, funs(sum(is.na(.)))) %>%
mutate(n = n() - sum(is.na(.)))
SS_Water %>%%>%
SS_Water %>%%>%
SS_Water %>%%>%
SS_Water %>%
summarise_if(is.numeric, funs(n(.)))
SS_Water %>%
summarise_if(is.numeric, funs(n()))
SS_Water %>%
summarise_if(is.numeric, funs(sum(is.na(.))))
SS_Water %>%
summarise_if(is.numeric, funs(5366-sum(is.na(.))))
# There are 5366 rows in the df
SS_Water %>%
summarise_if(is.numeric, funs(5366-sum(is.na(.))))
SS_Water <- SS_Water %>% select(!c(diazinon_oxon, sodium, atrazine_degradate, fipronil_amide, electricalconductivity, diazinon_degradate))
SS_Water %>%
summarise_if(is.numeric, funs(5366-sum(is.na(.))))
### Create dataframe with just Stressors (response variables here)
SS_Stressor <- SS_Water %>% select(!c(Region, Matrix, Seasonr, PercHighIntens, PercAgri))
SS_Source <- SS_Water %>% select(Region, Matrix, Seasonr, PercHighIntens, PercAgri)
library(MASS)
seasonr_lda <- lda(SS_Stressor, grouping = SS_Water$Seasonr)
seasonr_lda <- lda(SS_Stressor, grouping = SS_Water$Seasonr, na.pass)
seasonr_lda <- lda(SS_Stressor, grouping = SS_Water$Seasonr, na.action = na.pass)
seasonr_lda <- lda(SS_Stressor, grouping = SS_Water$Seasonr, na.exclude)
View(SS_Water)
SS_Water$Seasonr
unique(SS_Water$Seasonr)
seasonr_lda <- lda(SS_Stressor, grouping = SS_Water$Seasonr, na.exclude)
summarise(SS_Water$Seasonr)
SS_Water$Seasonr <- as.factor(SS_Water$Seasonr)
seasonr_lda <- lda(SS_Stressor, grouping = SS_Water$Seasonr, na.exclude)
seasonr_lda <- lda(SS_Stressor, grouping = SS_Water$Seasonr, na.action = na.pass)
seasonr_lda <- lda(SS_Stressor, grouping = SS_Water$Seasonr, na.exclude)
seasonr_lda <- lda(SS_Stressor, grouping = SS_Water$Seasonr, na.pass)
seasonr_lda <- lda(SS_Stressor, grouping = SS_Water$Seasonr, na.action(na.pass))
seasonr_lda <- lda(SS_Stressor, grouping = SS_Water$Seasonr, na.action(na.omit))
seasonr_lda <- lda(SS_Stressor, grouping = SS_Water$Seasonr, na.action(na.omit(c(1,NA))))
corr <- round(cor(SS_Stressor), 1)
SS_Water <- SS_Water %>% select(!c(diazinon_oxon, sodium, atrazine_degradate, fipronil_amide, electricalconductivity, diazinon_degradate))
## Subset Stressors (response variables here)
SS_Stressor <- SS_Water %>% select(!c(Region, Matrix, Seasonr, PercHighIntens, PercAgri))
View(SS_Water)
View(SS_Stressor)
View(SS_Stressor)
## Subset Numeric
SS_Num <- SS_Water %>% select(!c(Region, Matrix, Seasonr, Season01))
library(tidyverse)
library(sf)
library(here)
library(readxl)
library(vegan)
library(MASS)
# Read in wide-format data with Source and Stressor both.
SS_Water <- read_csv("Data/Output/AllWater_ForNetica.csv") %>% na_if(., "*")
# All variables except character v's - some listed as character even though numeric. Fix that.
SS_Water[c(2:33, 37:38)] <- SS_Water[c(2:33, 37:38)] %>%
mutate_if(is.character,as.numeric)
# Define factors
SS_Water$Region <- as.factor(SS_Water$Region)
# There are 5366 rows in the df
SS_Water %>%
summarise_if(is.numeric, funs(5366-sum(is.na(.))))
SS_Water <- SS_Water %>% select(!c(diazinon_oxon, sodium, atrazine_degradate, fipronil_amide, electricalconductivity, diazinon_degradate))
View(SS_Water)
SS_Water <- SS_Water %>% select(!c(diazinon_oxon, sodium, atrazine_degradate, fipronil_amide, electricalconductivity, diazinon_degradate))
View(SS_Water)
SS_Water <- SS_Water %>% select(!any_of(Insufficient))
SS_Water <- SS_Water %>% select(-any_of(Insufficient))
SS_Water <- SS_Water %>% select(!names(SS_Water) %in% Insufficient)
View(SS_Water)
library(tidyverse)
SS_Water <- read_csv("Data/Output/AllWater_ForNetica.csv") %>% na_if(., "*")
# All variables except character v's - some listed as character even though numeric. Fix that.
SS_Water[c(2:33, 37:38)] <- SS_Water[c(2:33, 37:38)] %>%
mutate_if(is.character,as.numeric)
# Define factors
SS_Water$Region <- as.factor(SS_Water$Region)
SS_Water <- SS_Water %>% select(!names(SS_Water) %in% Insufficient)
SS_Water <- SS_Water %>% select(!Insufficient)
Insufficient <- c("diazinon_oxon", "sodium", "atrazine_degradate", "fipronil_amide", "electricalconductivity", "diazinon_degradate")
SS_Water <- SS_Water %>% select(!names(SS_Water) %in% Insufficient)
SS_Water <- SS_Water %>% select(!any_of(Insufficient))
Drop <- c("diazinon_oxon", "sodium", "atrazine_degradate", "fipronil_amide", "electricalconductivity", "diazinon_degradate")
SS_Water <- SS_Water %>% select(!any_of(Drop))
SS_Water <- SS_Water %>% select(!!any_of(Drop))
SS_Water <- SS_Water %>% select(-any_of(Drop))
SS_Water <- SS_Water %>% select(-Drop)
SS_Water <- SS_Water %>% select(-sodium)
SS_Water <- SS_Water %>% select(sodium)
